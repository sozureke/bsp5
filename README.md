# AEGIS: Multi-Agent RL for Communication-Deduction Games

A production-quality multi-agent reinforcement learning project implementing a communication-deduction game with trust-mediated communication. Features PettingZoo + Gymnasium environments, NetworkX-based pathfinding, and CleanRL PPO training.

## Features

- **Two Roles**: Survivors and Impostors with distinct objectives and actions
- **Trust-Based Communication**: Discrete actions (SUPPORT, ACCUSE, DEFEND, QUESTION) that influence voting through a trust matrix
- **Partial Observability**: Configurable vision radius limits what agents can see
- **Meeting/Voting**: Body reports trigger discussion and voting phases with confidence-based filtering

## Resources

- ðŸ“„ [Research Paper](https://drive.google.com/file/d/1xYKkFJ_mdL9Z7fnjBOm9tBaw4GyBeqyH/view?usp=sharing) - Full paper describing the methodology and results
- ðŸ’¾ [Pre-trained Checkpoints](https://drive.google.com/drive/folders/1tp2Q9C0M6Q_Mbt9wbMndBVBv9c3u-Yle?usp=sharing) - Download trained models for all experiments (E1-E4)

## Installation

```bash
# Install in development mode
cd aegis
pip install -e .
```

## Quick Start

### Train a Single Experiment

```bash
# Training with config file
python -m aegis.train.rl_ppo -c aegis/train/configs/e3_trust_comm.config.yaml
```

### Run Multiple Experiments

```bash
# Run experiment with all seeds (200 seeds)
python -m aegis.scripts.run_experiments e3_trust_comm.config.yaml

# Run multiple experiments
python -m aegis.scripts.run_experiments e1_baseline.config.yaml e3_trust_comm.config.yaml

# Run with test seeds (first 10 seeds, for quick testing)
python -m aegis.scripts.run_experiments e1_baseline.config.yaml --test
```

## Experiments

The project includes controlled ablation experiments studying trust-mediated communication:

| Experiment | Config File | Description | Key Variable |
|------------|-------------|-------------|--------------|
| **E1: Baseline** | `e1_baseline.config.yaml` | No communication, no trust | `enable_trust_comm: false` |
| **E2: FoV Low** | `e2_fov_low.config.yaml` | Limited visibility with communication | `vision_radius: 1` |
| **E2: FoV High** | `e2_fov_high.config.yaml` | Extended visibility with communication | `vision_radius: 3` |
| **E3: Trust + Comm** | `e3_trust_comm.config.yaml` | Main condition with trust filtering | `trust_delay_ticks: 1` |
| **E4: Delay Immediate** | `e4_delay_immediate.config.yaml` | Immediate trust updates | `trust_delay_ticks: 0` |
| **E4: Delay Delayed** | `e4_delay_delayed.config.yaml` | Delayed trust updates | `trust_delay_ticks: 5` |

Additional experiments (E5, E6, E7) are available in `train/configs/extra/`.

## Analysis

After running experiments, analyze results:

```bash
# Merge events from all seeds
python -m aegis.analysis.merge_events checkpoints/e3_trust_comm

# Aggregate metrics from all experiments
python -m aegis.analysis.aggregate_all_metrics

# Generate plots
python -m aegis.analysis.plot_metrics

# Analyze events
python -m aegis.analysis.analyze_events checkpoints/e3_trust_comm/events_all.jsonl --summary
```

## Project Structure

```
aegis/
â”œâ”€â”€ core/              # Game engine, world state, rules
â”œâ”€â”€ obs/               # Observation builders and spaces
â”œâ”€â”€ comms/             # Communication actions and trust system
â”œâ”€â”€ agents/            # Agent policies (heuristic, random)
â”œâ”€â”€ logging/           # Event logging and metrics
â”œâ”€â”€ train/             # PPO training and experiment configs
â”‚   â”œâ”€â”€ rl_ppo.py      # Main training entry point
â”‚   â”œâ”€â”€ seeds.py       # Shared seed set for experiments
â”‚   â””â”€â”€ configs/       # Experiment configurations
â”‚       â””â”€â”€ extra/     # Additional experiments (E5, E6, E7)
â”œâ”€â”€ scripts/           # Experiment execution
â”‚   â””â”€â”€ run_experiments.py
â””â”€â”€ analysis/          # Result analysis and visualization
    â”œâ”€â”€ aggregate_all_metrics.py
    â”œâ”€â”€ analyze_events.py
    â”œâ”€â”€ merge_events.py
    â”œâ”€â”€ plot_metrics.py
    â””â”€â”€ evaluate_ppo.py
```

## Results

Pre-trained checkpoints for all experiments are available for download (see [Resources](#resources) above).

When training locally, results are saved in:
- `checkpoints/<experiment>/seed_<N>/` - Individual seed results
- `checkpoints/<experiment>/events_all.jsonl` - Merged events (after running merge_events)
- `results/all_metrics.json` - Aggregated metrics (after running aggregate_all_metrics)
- `results/plots/` - Visualization plots (after running plot_metrics)

## Fixed Parameters

All experiments use identical parameters except for the variables being tested:
- **Agents**: 4 survivors + 2 impostors per episode
- **Map**: 9 rooms (3Ã—3 grid), evac_room=4
- **Episode length**: Maximum 600 ticks
- **Meetings**: 80 ticks discussion + 40 ticks voting
- **Training**: 2,000,000 timesteps, PPO with fixed hyperparameters
- **Seeds**: Shared set of 200 seeds for paired comparison
- **Vision radius**: Fixed to 2 (except E2: 1 and 3)

## License

MIT License

## Author

Marshanishvili Mykhailo, University of Luxembourg
